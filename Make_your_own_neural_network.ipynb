{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages of Python that we will/may use in this notebook\n",
    "# pandas and numpy for dataframe creation and manipulation\n",
    "# matplot lib for data visualization\n",
    "# sklearn for statistical algorithms and splitting the dataset to training and testing datasets\n",
    "\n",
    "# General\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Features pre-processing and principal component analysis (pca)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "# Classifiers ensembling\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# Classifiers evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, auc, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Random resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Tuning hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Other\n",
    "from time import time\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Ploting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import namedtuple\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "\n",
    "\n",
    "# Suppressing annoying harmless error\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the local drive\n",
    "\n",
    "safe_driver = pd.read_excel('IT_3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                                     0.000\n",
       "target                                                                 0.000\n",
       "Gender                     FFMMMFFFFFMFFFMMMFMFMMMMFFMMMFMFMMMFFMMFMMMMMM...\n",
       "EngineHP                                                               0.000\n",
       "credit_history                                                         0.000\n",
       "Years_Experience                                                       0.000\n",
       "annual_claims                                                          0.000\n",
       "Marital_Status             MarriedMarriedMarriedMarriedMarriedMarriedMarr...\n",
       "Vehicle_Type               CarCarVanVanVanTruckTruckCarCarTruckUtilityTru...\n",
       "Miles_driven_annually                                                  0.000\n",
       "size_of_family                                                         0.000\n",
       "Age_bucket                 <1828-34>4018-27>40>40>40>40>4035-40>4035-40>4...\n",
       "EngineHP_bucket            >350>35090-16090-16090-16090-16090-160<90>3509...\n",
       "Years_Experience_bucket    <315-3015-309-14'>3015-30>3015-30>3015-3015-30...\n",
       "credit_history_bucket      FairGoodGoodGoodVery GoodGoodVery GoodVery Goo...\n",
       "State                      ILNJCTCTWYDENJMECANJKSCTWVCTCTNMSCWYCTCANJCTID...\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data has any negaitve values\n",
    "\n",
    "safe_driver.where(safe_driver < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30240 entries, 0 to 30239\n",
      "Data columns (total 17 columns):\n",
      "ID                              30240 non-null int64\n",
      "target                          30240 non-null int64\n",
      "Gender                          30240 non-null object\n",
      "EngineHP                        30240 non-null int64\n",
      "credit_history                  30240 non-null int64\n",
      "Years_Experience                30240 non-null int64\n",
      "annual_claims                   30240 non-null int64\n",
      "Marital_Status                  30240 non-null object\n",
      "Vehicle_Type                    30240 non-null object\n",
      "Miles_driven_annually           30232 non-null float64\n",
      "size_of_family                  30240 non-null int64\n",
      "Age_bucket                      30240 non-null object\n",
      "EngineHP_bucket                 30240 non-null object\n",
      "Years_Experience_bucket         30240 non-null object\n",
      "Miles_driven_annually_bucket    30232 non-null object\n",
      "credit_history_bucket           30240 non-null object\n",
      "State                           30240 non-null object\n",
      "dtypes: float64(1), int64(7), object(9)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any NULL data that need to be dropped\n",
    "safe_driver.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30240.000</td>\n",
       "      <td>30240.000</td>\n",
       "      <td>30240.000</td>\n",
       "      <td>30240.000</td>\n",
       "      <td>30240.000</td>\n",
       "      <td>30240.000</td>\n",
       "      <td>30232.000</td>\n",
       "      <td>30240.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15120.500</td>\n",
       "      <td>0.708</td>\n",
       "      <td>196.604</td>\n",
       "      <td>685.770</td>\n",
       "      <td>13.256</td>\n",
       "      <td>1.138</td>\n",
       "      <td>17422.939</td>\n",
       "      <td>4.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8729.680</td>\n",
       "      <td>0.455</td>\n",
       "      <td>132.347</td>\n",
       "      <td>102.454</td>\n",
       "      <td>9.890</td>\n",
       "      <td>1.083</td>\n",
       "      <td>17483.783</td>\n",
       "      <td>2.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>300.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7560.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>111.000</td>\n",
       "      <td>668.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9668.500</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15120.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>141.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12280.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22680.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>238.000</td>\n",
       "      <td>753.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14697.250</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30240.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1005.000</td>\n",
       "      <td>850.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>99943.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    target  EngineHP  credit_history  Years_Experience  \\\n",
       "count 30240.000 30240.000 30240.000       30240.000         30240.000   \n",
       "mean  15120.500     0.708   196.604         685.770            13.256   \n",
       "std    8729.680     0.455   132.347         102.454             9.890   \n",
       "min       1.000     0.000    80.000         300.000             1.000   \n",
       "25%    7560.750     0.000   111.000         668.000             5.000   \n",
       "50%   15120.500     1.000   141.000         705.000            10.000   \n",
       "75%   22680.250     1.000   238.000         753.000            20.000   \n",
       "max   30240.000     1.000  1005.000         850.000            40.000   \n",
       "\n",
       "       annual_claims  Miles_driven_annually  size_of_family  \n",
       "count      30240.000              30232.000       30240.000  \n",
       "mean           1.138              17422.939           4.521  \n",
       "std            1.083              17483.783           2.287  \n",
       "min            0.000               5000.000           1.000  \n",
       "25%            0.000               9668.500           3.000  \n",
       "50%            1.000              12280.000           5.000  \n",
       "75%            2.000              14697.250           7.000  \n",
       "max            4.000              99943.000           8.000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_driver.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Claims is  21396\n",
      "Total number of records is 30240\n",
      "The percentage of true claims is 71.0%\n"
     ]
    }
   ],
   "source": [
    "# Check and see if we have an imbalanced class label in the dataset\n",
    "# Calculate the percentage of success data ('target' == 1) with respect to the failure data ('target' == 0)\n",
    "\n",
    "true_claims = (safe_driver['target'] == 1).sum()\n",
    "print('True Claims is  {}'.format(true_claims))\n",
    "\n",
    "total_records = len(safe_driver['target'])\n",
    "print('Total number of records is {}'.format(total_records))\n",
    "\n",
    "print('The percentage of true claims is {}%'.format(\n",
    "    round(true_claims / total_records * 100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is indeed imbalanced. We will balance it later using SMOTE technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains several categorical data that ends with `_bucket` that need to be either dropped or converted to numerical values using dummies. All features that are of type object are categorical variables that needs to either:<br>\n",
    "<br>\n",
    "a. Converted to numeric using dummies<br>\n",
    "b. Dropped or<br>\n",
    "c. Assigned a binary value<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gender', 'Marital_Status', 'Vehicle_Type', 'Age_bucket',\n",
      "       'EngineHP_bucket', 'Years_Experience_bucket',\n",
      "       'Miles_driven_annually_bucket', 'credit_history_bucket', 'State'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_features = safe_driver.select_dtypes(include=['object']).copy()\n",
    "print(cat_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the categorical variables we retain the following:<br>\n",
    "<br>\n",
    "1. Gender<br>\n",
    "2. Marital_Status<br>\n",
    "3. Vehicle_Type, and<br>\n",
    "4. Age_bucket<br>\n",
    "<br>\n",
    "EngineHP_bucket, Years_Experience_bucket, Miles_driven_annually_bucket, credit_history_bucket have a corresponding continuous variable. Creating each with their own dummies along with the continuous variable does not make sense. We will keep the Age_bucket as there is no continuous variable to represent age.<br>\n",
    "<br>\n",
    "We can split the dataset by State (one sub-dataset for each state) and analyze each state by itself. As each US state has its own regulations it may make sense to analyze each state by itself. We could aggregate our results across states later to get a national statistic.<br>\n",
    "<br>\n",
    "Or, for now, we could drop the State column and analyze the data across the nation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these 5 columns: ID, EngineHP_bucket, Years_Experience_bucket, Miles_driven_annually_bucket, credit_history_bucket\n",
    "\n",
    "safe_driver.drop(['ID', 'EngineHP_bucket', 'Years_Experience_bucket',\n",
    "                  'Miles_driven_annually_bucket',\n",
    "                  'credit_history_bucket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                   0\n",
       "Gender                   0\n",
       "EngineHP                 0\n",
       "credit_history           0\n",
       "Years_Experience         0\n",
       "annual_claims            0\n",
       "Marital_Status           0\n",
       "Vehicle_Type             0\n",
       "Miles_driven_annually    8\n",
       "size_of_family           0\n",
       "Age_bucket               0\n",
       "State                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the dataset has any NaN values as these values will make our algorithms throw an exception\n",
    "\n",
    "safe_driver.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Miles_driven_annually feature has some null values. Let us explore which particular cells have NaN and ingest them with the median data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "      <th>Age_bucket</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>124</td>\n",
       "      <td>793</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>465</td>\n",
       "      <td>696</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>8</td>\n",
       "      <td>18-27</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>137</td>\n",
       "      <td>787</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18158</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>108</td>\n",
       "      <td>747</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>18-27</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19795</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>121</td>\n",
       "      <td>774</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>28-34</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25731</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>355</td>\n",
       "      <td>694</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>28-34</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>109</td>\n",
       "      <td>743</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27045</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>784</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Truck</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target Gender  EngineHP  credit_history  Years_Experience  \\\n",
       "1235        1      F       124             793                27   \n",
       "7365        0      F       465             696                 5   \n",
       "11464       1      F       137             787                18   \n",
       "18158       0      F       108             747                 8   \n",
       "19795       1      F       121             774                19   \n",
       "25731       1      F       355             694                15   \n",
       "26512       1      F       109             743                40   \n",
       "27045       1      F        83             784                21   \n",
       "\n",
       "       annual_claims Marital_Status Vehicle_Type  Miles_driven_annually  \\\n",
       "1235               0        Married        Truck                    nan   \n",
       "7365               0        Married        Truck                    nan   \n",
       "11464              1        Married        Truck                    nan   \n",
       "18158              1        Married        Truck                    nan   \n",
       "19795              0        Married        Truck                    nan   \n",
       "25731              1        Married        Truck                    nan   \n",
       "26512              0        Married        Truck                    nan   \n",
       "27045              0        Married        Truck                    nan   \n",
       "\n",
       "       size_of_family Age_bucket State  \n",
       "1235                3        >40    NJ  \n",
       "7365                8      18-27    SD  \n",
       "11464               1        >40    CT  \n",
       "18158               1      18-27    OR  \n",
       "19795               2      28-34    NY  \n",
       "25731               5      28-34    CT  \n",
       "26512               1        >40    OR  \n",
       "27045               1        >40    CT  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_driver[safe_driver.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may make sense to ingest the median of  `Vehicle_Type=='Truck'` as all the NaN values are for Truck only. Let us look at the median of Miles_driven_annually by each vehicle type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>695</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13147.500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truck</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>694</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12370.500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utility</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>741</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11117.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Van</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>721</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>11272.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target  EngineHP  credit_history  Years_Experience  \\\n",
       "Vehicle_Type                                                       \n",
       "Car                1       148             695                 7   \n",
       "Truck              1       150             694                 8   \n",
       "Utility            1       132             741                14   \n",
       "Van                1       128             721                15   \n",
       "\n",
       "              annual_claims  Miles_driven_annually  size_of_family  \n",
       "Vehicle_Type                                                        \n",
       "Car                       1              13147.500               4  \n",
       "Truck                     1              12370.500               5  \n",
       "Utility                   1              11117.000               5  \n",
       "Van                       1              11272.000               5  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_values = safe_driver.groupby('Vehicle_Type').median()\n",
    "median_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in Miles_driven_annually with the median value for Truck\n",
    "# There may be better ways to impute missing data. But we have just 8 NaN cells out of some 30,000+ rows which is\n",
    "# less than 0.03%\n",
    "# So, imputing with median for all the 8 cells is not going to skew our results.\n",
    "\n",
    "safe_driver.fillna(\n",
    "    median_values.loc['Truck', 'Miles_driven_annually'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "      <th>Age_bucket</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [target, Gender, EngineHP, credit_history, Years_Experience, annual_claims, Marital_Status, Vehicle_Type, Miles_driven_annually, size_of_family, Age_bucket, State]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values again to make sure we did not miss any accidentally\n",
    "\n",
    "safe_driver[safe_driver.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30240 entries, 0 to 30239\n",
      "Data columns (total 12 columns):\n",
      "target                   30240 non-null int64\n",
      "Gender                   30240 non-null object\n",
      "EngineHP                 30240 non-null int64\n",
      "credit_history           30240 non-null int64\n",
      "Years_Experience         30240 non-null int64\n",
      "annual_claims            30240 non-null int64\n",
      "Marital_Status           30240 non-null object\n",
      "Vehicle_Type             30240 non-null object\n",
      "Miles_driven_annually    30240 non-null float64\n",
      "size_of_family           30240 non-null int64\n",
      "Age_bucket               30240 non-null object\n",
      "State                    30240 non-null object\n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of all remaining features\n",
    "\n",
    "safe_driver.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature values above, the range of values of each vary a lot. For example `'Miles_driven_annually'` is in the 10s of thousands, whereas 'credit_history' is in the 100s and 'annual-claims' is in single digit. Due to the varying magnitudes of the feature values we will scale the features with Z-scores using `sklearn.preprocessing.scale`.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To standardize the numeric features we need to isolate them first into a separate dataframe\n",
    "\n",
    "safe_driver_num_features = safe_driver.drop(\n",
    "    safe_driver.select_dtypes(['object']), axis=1)\n",
    "\n",
    "# Do not standardize 'target' which is our label\n",
    "\n",
    "safe_driver_num_features.drop(['target'], axis=1, inplace=True)\n",
    "\n",
    "safe_driver_cat_features = safe_driver.select_dtypes(['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Restore the column names from the original dataset\n",
    "\n",
    "safe_driver_scaled = pd.DataFrame(preprocessing.scale(safe_driver_num_features),\n",
    "                                  columns=safe_driver_num_features.columns)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "safe_driver_scaled = pd.DataFrame(scaler.fit_transform(\n",
    "    safe_driver_num_features), columns=safe_driver_num_features.columns)\n",
    "\n",
    "# We now have the scaled feature set. Now we need to concatenate the categorical features back with our scaled\n",
    "# dataset before running OneHotEncoder or dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will concatenate the scaled dataframe with the categorical feature set\n",
    "\n",
    "safe_driver = pd.concat(\n",
    "    [safe_driver_scaled, safe_driver['target'], safe_driver_cat_features], axis=1)\n",
    "\n",
    "# We will add the 'target' label back to the scaled dataframe as we may need it later\n",
    "safe_driver_scaled = pd.concat(\n",
    "    [safe_driver_scaled, safe_driver['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EngineHP, credit_history, Years_Experience, annual_claims, Miles_driven_annually, size_of_family]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any NaN values one more time\n",
    "\n",
    "safe_driver_num_features[safe_driver_num_features.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_driver_num_features = pd.concat(\n",
    "    [safe_driver_num_features, safe_driver['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Gender to a 1 or a 2\n",
    "safe_driver['Gender'] = np.where(safe_driver['Gender'] == 'F', 1, 2)\n",
    "\n",
    "# Convert Marital_Status to a 1 or a 2\n",
    "safe_driver['Marital_Status'] = np.where(\n",
    "    safe_driver['Marital_Status'] == 'Single', 1, 2)\n",
    "\n",
    "# Convert Vehicle_Type using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(safe_driver['Vehicle_Type'])\n",
    "\n",
    "safe_driver['Vehicle_Type'] = le.transform(safe_driver['Vehicle_Type'])\n",
    "\n",
    "# Convert Age_bucket using LabelEncoder\n",
    "le.fit(safe_driver['Age_bucket'])\n",
    "\n",
    "safe_driver['Age_bucket'] = le.transform(safe_driver['Age_bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "      <th>target</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th>Age_bucket</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EngineHP  credit_history  Years_Experience  annual_claims  \\\n",
       "0     0.478           0.647             0.000          0.000   \n",
       "1     0.661           0.735             0.385          0.000   \n",
       "2     0.057           0.711             0.359          0.000   \n",
       "3     0.071           0.764             0.205          0.000   \n",
       "4     0.052           0.856             0.821          0.250   \n",
       "5     0.069           0.767             0.436          0.250   \n",
       "6     0.077           0.887             0.769          0.750   \n",
       "7     0.009           0.813             0.513          0.250   \n",
       "8     0.619           0.758             0.846          0.000   \n",
       "9     0.043           0.882             0.462          0.250   \n",
       "\n",
       "   Miles_driven_annually  size_of_family  target  Gender  Marital_Status  \\\n",
       "0                  0.103           0.571       1       1               2   \n",
       "1                  0.109           0.714       1       1               2   \n",
       "2                  0.052           0.286       1       2               2   \n",
       "3                  0.762           0.286       1       2               2   \n",
       "4                  0.097           0.429       1       2               2   \n",
       "5                  0.076           1.000       1       1               2   \n",
       "6                  0.094           0.143       1       1               2   \n",
       "7                  0.097           0.571       1       1               1   \n",
       "8                  0.127           0.000       1       1               2   \n",
       "9                  0.012           0.000       0       1               2   \n",
       "\n",
       "   Vehicle_Type  Age_bucket State  \n",
       "0             0           3    IL  \n",
       "1             0           1    NJ  \n",
       "2             3           4    CT  \n",
       "3             3           0    CT  \n",
       "4             3           4    WY  \n",
       "5             1           4    DE  \n",
       "6             1           4    NJ  \n",
       "7             0           4    ME  \n",
       "8             0           4    CA  \n",
       "9             1           2    NJ  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_driver.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'target' column from training dataframe as that is our label\n",
    "X = safe_driver.drop(['target', 'State'], 1)\n",
    "\n",
    "# The 'target' column is our label or outcome that we want to predict\n",
    "y = safe_driver['target']\n",
    "\n",
    "# Drop and NaN values\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  42792\n",
      "Number of negative class in oversampled data 21396\n",
      "Number of positive class in oversampled data 21396\n",
      "Proportion of negative class in oversampled data is  0.5\n",
      "Proportion of positive class in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os = SMOTE(random_state=0)\n",
    "\n",
    "columns = X.columns\n",
    "os_data_X, os_data_y = os.fit_sample(X, y)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "os_data_y = pd.DataFrame(data=os_data_y, columns=['y'])\n",
    "\n",
    "# Split the resulting balanced data set as train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    os_data_X, os_data_y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Check the size of our new data\n",
    "print(\"length of oversampled data is \", len(os_data_X))\n",
    "print(\"Number of negative class in oversampled data\",\n",
    "      len(os_data_y[os_data_y['y'] == 0]))\n",
    "print(\"Number of positive class in oversampled data\",\n",
    "      len(os_data_y[os_data_y['y'] == 1]))\n",
    "print(\"Proportion of negative class in oversampled data is \",\n",
    "      len(os_data_y[os_data_y['y'] == 0])/len(os_data_X))\n",
    "print(\"Proportion of positive class in oversampled data is \",\n",
    "      len(os_data_y[os_data_y['y'] == 1])/len(os_data_X))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the resulting balanced data set as train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(os_data_X, os_data_y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gradient Boosting Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=10,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "Training set score: 0.9001135073779796\n"
     ]
    }
   ],
   "source": [
    "# Finally, we try GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(loss='deviance', max_depth=10)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "print(clf_model)\n",
    "print('Training set score:', clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Each Cross Validated Accuracy: \n",
      " [0.74399199 0.7325989  0.74561843 0.73789649 0.74123539]\n",
      "\n",
      "Overall Gradient Boosted Classifier Accuracy: 0.74 (+/- 0.01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLF_score = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print('\\nEach Cross Validated Accuracy: \\n', CLF_score)\n",
    "print(\"\\nOverall Gradient Boosted Classifier Accuracy: %0.2f (+/- %0.2f)\\n\" %\n",
    "      (CLF_score.mean(), CLF_score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_test_score = cross_val_score(clf, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12127,  2851],\n",
       "       [  141, 14835]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = clf.predict(X_train)\n",
    "target_names = ['Safe Driver', 'Non-safe Driver']\n",
    "GB_scores = classification_report(\n",
    "    y_train, y_predict, target_names=target_names, output_dict=True)\n",
    "confusion_matrix(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using MLP features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58      6418\n",
      "           1       0.56      0.50      0.53      6420\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     12838\n",
      "   macro avg       0.56      0.56      0.56     12838\n",
      "weighted avg       0.56      0.56      0.56     12838\n",
      "\n",
      "\n",
      "Logistic regression using GBM features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70      6418\n",
      "           1       0.69      0.89      0.78      6420\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     12838\n",
      "   macro avg       0.77      0.74      0.74     12838\n",
      "weighted avg       0.77      0.74      0.74     12838\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#from skimage import color\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2000,))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Compare MLP and GBM models\n",
    "print(\"Logistic regression using MLP features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        y_test,\n",
    "        mlp.predict(X_test))))\n",
    "\n",
    "print(\"Logistic regression using GBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        y_test,\n",
    "        clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5936435868331441"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5288162 , 0.52803738, 0.52258567, 0.53992988, 0.52201013])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(2000,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
