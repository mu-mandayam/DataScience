{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20052.000000\n",
       "mean         3.714467\n",
       "std          1.340829\n",
       "min          0.000000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our label ('rating') from regression to a binary classifier using the mean value\n",
    "# if rating is > mean then 1 else 0\n",
    "\n",
    "rating_mean = raw_data.rating.mean()\n",
    "\n",
    "raw_data.loc[raw_data.rating >= rating_mean, 'rating'] = 1\n",
    "raw_data.loc[raw_data.rating > 1, 'rating'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the title column as it is a text data and does not contribute as a feature or label\n",
    "\n",
    "raw_data.drop(['title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any NaN values to zeros\n",
    "\n",
    "raw_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our feature set and label data\n",
    "\n",
    "X = raw_data.drop(['rating'], axis=1)\n",
    "y = raw_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size: The split between test and train is 80-20 approximately\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (17187, 678)\n",
      "transformed shape: (17187, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit our scaled data into PCA with 30 components\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "print(\"original shape:   \", X_train.shape)\n",
    "print(\"transformed shape:\", X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.19464719 -0.42740388 -2.11578795 ... -0.4748697  -1.036702\n",
      "   0.56278038]\n",
      " [ 2.2829558  -1.4099328  -1.13260134 ...  0.45742277  0.14786213\n",
      "   0.07513771]\n",
      " [ 1.7511687  -2.32851716 -0.80927018 ...  0.43053751  0.54695509\n",
      "   0.29107284]\n",
      " ...\n",
      " [-2.67276838  4.20281644 -3.44871182 ...  0.66715836 -0.01300972\n",
      "   0.34498622]\n",
      " [-2.44972997 -1.37441485  0.34976843 ...  1.59980523 -1.53900513\n",
      "   0.13233931]\n",
      " [-3.84256852 -0.98549957  1.07071244 ...  0.39185179  0.17281273\n",
      "   0.22217437]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80948226, 0.80628272, 0.80331685, 0.80331685, 0.80826302])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svr = SVC(gamma='auto')\n",
    "\n",
    "svr.fit(X_train_pca, y_train)\n",
    "\n",
    "predicted_labels = svr.predict(X_train_pca)\n",
    "#plt.scatter(y_train, predicted_labels)\n",
    "\n",
    "svr.score(X_train_pca, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svr, X_train_pca, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  838,  2742],\n",
       "       [   89, 13518]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the confusion matrix to see fp and tp\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    13607\n",
       "0.0     3580\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the original labels\n",
    "\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    16260\n",
       "0.0      927\n",
       "dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check predicted labels\n",
    "\n",
    "pd.Series(predicted_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
